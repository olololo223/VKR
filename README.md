# Мультимодальная система распознавания эмоций

## Описание

Современная система для распознавания эмоций, использующая передовые методы глубокого обучения:

- **Визуальная модальность**: Модель ResNet для анализа мимики
- **Аудиальная модальность**: Wav2Vec 2.0 для анализа голосовых паттернов
- **Мультимодальная модель**: Гибридная архитектура, объединяющая оба типа данных

## Структура проекта
```
VKR/ ├── data/ # Данные 
│ └── processed/ # Обработанные данные 
├── src/ │ ├── data_preprocessing/ # Предобработка данных 
│ ├── evaluation/ # Оценка моделей 
│ ├── models/ # Базовые архитектуры моделей 
│ ├── pre-trained_models/ # Предобученные модели 
│ │ ├── datasets/ # Наборы данных 
│ │ ├── fusion_model.py # Мультимодальная модель 
│ │ ├── resnet_model.py # ResNet для изображений 
│ │ └── wav2vec_model.py # Wav2Vec 2.0 для аудио 
│ ├── training/ # Скрипты обучения 
│ └── utils/ # Вспомогательные утилиты 
├── demo_gui.py # Графический интерфейс 
├── demo_realtime.py # Демо в реальном времени 
└── requirements.txt # Зависимости
```

## Установка

1. Клонируйте репозиторий и создайте виртуальное окружение:
```bash
git clone <repository-url>
cd VKR
bash
python -m venv venv
venv\Scripts\activate
```
Установите зависимости:
```bash
pip install -r requirements.txt
```
Использование
Демонстрация в реальном времени
```bash
python src/demo_realtime.py
```
Графический интерфейс
```bash
python src/demo_gui.py
```
Архитектура моделей:
- **Визуальная модель (ResNet)**
Основана на архитектуре ResNet
Принимает на вход изображения лиц
Возвращает вероятности эмоций
- **Аудио модель (Wav2Vec 2.0)**
Использует предобученную модель Wav2Vec 2.0
Анализирует голосовые паттерны
Возвращает вероятности эмоций
- **Мультимодальная модель**
Объединяет выходы визуальной и аудио моделей
Использует механизм внимания для взвешивания вклада каждой модальности
Возвращает финальное предсказание эмоции

Требования
Python 3.8+
PyTorch
Transformers
OpenCV
NumPy
PyQt5 (для GUI)